# Fedra

**_Il testo in corsivo da considerarsi come una vaga idea, senza fondamenta di approfondimento._**

## Scenario

- Degli amici sono in spiaggia a divertirsi. Per immortalare il momento decidono di realizzare una video (story) tutti insieme. Una volta registrato il video, l'applicazione chiede all'utente di aggiungere i tag delle altre persone o di confermare gli utenti suggeriti tramite analisi del video. Confermati i partecipanti del video, l'utente può decidere i filtri da applicare al video.
- La computazione dei filtri avviene in maniera distribuita tra i partecipanti del video, che divengono volunteer nella computazione previo opt-in da parte loro. Il dispositivo utente da cui avviene l'editing elabora i requisiti della computazione e può partecipare nella computazione nei limiti delle sue risorse. Invia dunque i requisiti ad un orchestratore che si occuperà di trovare le risorse adeguate ed eseguire la computazione fino al raggiungimento dell'obiettivo. La distribuzione della computazione è un compito che richiede trasmissione sia di dati (il video) che di funzioni in quanto i filtri sono scaricabili e realizzabili dagli utenti di Instagram a disposizione per tutti tramite l'applicazione.
- Tuttavia qualora il dispositivo mobile non sia dotato di hardware dedicato per le operazioni AI o abbiano batteria insufficiente, il software può richiedere la collaborazione di altri nodi nella rete dotati delle opportune risorse hardware (ad esempio GPU o CPU con istruzioni SIMD) tenendo in conto del vincolo di latenza.
- Ogni dispositivo del sistema che si registri come disponibile ad offrire computazione descrive le proprie capacità, fornendo informazioni quali potenza di calcolo disponibile e caratteristiche hardware come GPU, encoder/decoder di video/immagini, supporto istruzioni SIMD
- A seconda dei requisiti, ad esempio del filtro da applicare, un orchestratore decide quale nodo di computazione del sistema il più adatto, includendo se stesso tra le opzioni.
- All'improvviso i diversi ragazzi ricevono avvisi sui propri cellulari riguardo ad un imminente pioggia in arrivo grazie ai sensori di meteo di cui sono dotati le loro case. Si dirigono allora verso le proprie case.
- Nel tragitto uno di loro continua l'editing del video in macchina. I dispositivi mobile dei ragazzi rimangono partecipanti nella computazione, mentre altri nodi possono essere rimossi o aggiunti dinamicamente durante il movimento in base alla distanza fisica o alla latenza.
- Arrivati a casa di uno dei ragazzi, decidono di passare al desktop per avere uno schermo più grande con cui proseguire l'editing. A quel punto è il desktop che definisce i nuovi requisiti della computazione, sostituendo il dispositivo mobile che diviene semplice volunteer aggiuntivo e poiché sono collegati alla rete di casa, perfino il dispositivo IoT usato come sensore meteo può eseguire della computazione extra CPU o GPU.
- **Elementi innovativi**:
  - Computazione distribuita a partecipazione dinamica: i nodi volunteer non sono fissi a priori e non conoscono le funzioni prima di unirsi alla computazione. Lavori precedenti di questo genere sono nell'ambito del **Volunteer Computing**.
  - L'applicazione utente definisce i requisiti della computazione o potenzialmente sono gli utenti che definiscono i requisiti. Questo si distacca dall'approccio attuale ove i fornitori di servizi definiscono i requisiti e le dipendenze, tramite un file statico per un orchestratore come Kubernetes.
  - _Continuità dello stato della computazione. In questo caso il video a cui vengono applicati gli effetti rappresenta lo stato della computazione. Nel passaggio a desktop, l'utente prosegue l'editing del video senza dover esplicitamente caricare dal dispositivo mobile verso il desktop. Questo può essere possibile usando un Distributed File System._
  - Trasferimento di dati e funzioni. Le funzioni sono sia scaricabili dalla rete (pull) che trasmissibili da un nodo all'altro (push). **MapReduce** è un'architettura di questo genere, dove tuttavia le funzioni non sono portabili su dispositivi etereogenei con runtime diversi.
  - Continuità di computazione: tutti i nodi della rete possono offrire computazione e allo stesso tempo scaricare parte di computazione verso altri nodi.

## Architettura

![](images/architecture.png)

- Una **Application** è un software che ha necessità di risorse per raggiungere un obiettivo. Può essere ad esempio un'applicazione web, mobile o microservice in cloud. Un'applicazione è composta di **Task**, la cui rappresentazione è una **funzione**. Il media type di questa rappresentazione è WASM.
  - Le funzioni sono registrate nel **Functions Repository** al momento da parte dell'Application.
  - Un **Requirement** è una descrizione formale delle risorse, attualmente solo di computazione, richieste da una Application. Contiene le informazioni sulle funzioni quali i requisiti di memoria RAM di ciascuna funzione, le capabilities richieste (ad esempio TCP handle), e potenzialmente altre informazioni come la descrizione delle dipendenze tra funzioni.
    - Vi sono diversi modi di specificare le dipendenze tra funzioni, ad esempio come gruppi di Task dipendenti nello stesso nodo (Pod) in Kubernetes, oppure come grafo nel caso di Microsoft Apollo.
    - Un altro esempio di Requirement potrebbe essere [AWS Cloudformation](https://aws.amazon.com/it/cloudformation/), che offre sia API che template statico per fare provisioning automatico delle risorse necessarie in un sistema distribuito su AWS.
    - L'esempio preferito attualmente è il modello **MapReduce** di Google. Permette alle applicazioni di descrivere facilmente una specifica della computazione tramite combinazione di funzioni Map `(key, value) => list(key, value)` e Reduce `(key, list(value)) => list(value)`.
      - Fornisce un modello di programmazione semplice senza che le applicazioni debbano preoccuparsi dei problemi della computazione distribuita.
      - È un modello di computazione distribuita che si è dimostrata flessibile per diverse tipologie di problemi, compreso di Machine Learning.
      - Si presta bene anche come caso d'uso per il resto dell'architettura. I nodi **Workers** ricevono in ingresso i dati input e la funzione Map/Reduce.
      - Chi si occupa però dell'orchestrazione delle funzioni MapReduce? Ovvero c'è bisogno di assegnare le funzioni Map ed i dati ai Workers, aggregare gli output intermedi, fare split di questi per chiave ed inviati ai Worker con funzioni Reduce. Non può essere l'**Orchestrator** classico alla Kubernetes in quanto è generico rispetto all'Application ed inoltre non potrebbe contenere tutti gli stati di computazione delle diverse Application. La scelta ritenuta più ragionevole al momento è utilizzare uno **scheduling a due livelli**, diviso in **Application Scheduler** e **Resource Scheduler**. Descritto più in avanti.
      - Rimane comunque il problema di dove salvare i dati di computazione intermedi. Se si suppone che le Application avranno requisiti compute-intensive e non data-intensive si potrebbe salvare lo stato intermedio nell'Application Scheduler. Questo però limiterebbe il genere di applicazioni eseguibili nel sistema. Un'altra alternativa sarebbe usare nodi storage, ad esempio un nodo Blob Storage o Key-Value Storage, ma questi in genere sono presenti in datacenter del cloud. *Invece un distributed file system (DFS) potrebbe essere la soluzione migliore*.
    - *Invece di inviare la coppia dati input ("raw") e funzione (tramite URL), si potrebbe inviare la tripletta dati input, funzione e locazione dell'output tutto tramite URL. L'URL quindi permette anche di definire il protocollo e locazione dove poter leggere o salvare i dati. L'idea arriva dal concetto ["Everything is a URL" di Redox](https://doc.redox-os.org/book/ch04-04-urls.html).* Un altro esempio sono i pre-signed URLs di AWS che permettono di leggere e scrivere in maniera ristretta sullo storage S3.
- **Functions Repository**: è un registro delle funzioni identificabili in maniera univoca come risorsa URL. Le funzioni hanno una scadenza automatica se non sono state usate ad esempio nelle ultime 24h. Il Repository è geograficamente vicino ai Workers per migliorare il tempo di risposta.
- L'**Orchestrator** è diviso in due livelli. Il livello **Application Scheduler** si occupa di fare scheduling delle funzioni, mentre il **Resource Scheduler** è responsabile dell'assegnazione dei nodi Workers e del monitoraggio del loro stato di disponibilità. L'architettura è ispirata da Apache Mesos.
  - Questa architettura rende flessibile lo scheduling dei Workers per diversi tipi di Application. In particolare funziona meglio per tipologie di tasks a breve termine, che non occupino la risorsa a lungo. Questo sembra essere proprio il caso di Workers situati su nodi embedded o browser.
  - L'**Application Scheduler** riceve le informazioni dei nodi Worker disponibili e decide come assegnare le funzioni ai nodi. Punta a fare load balancing tra i Workers, ma allo stesso tempo cerca di fare cache-hit con Workers che abbiano già in cache la funzione per migliorare il tempo di risposta.
    - L'Application Scheduler **NON** è definito dal sistema, ovvero è definibile dagli utenti per permettere maggiore flessibilità di Applicazioni. Come fa però a definirlo? E su che nodi esegue? Come fa l'applicazione a conoscere l'Application Scheduler da contattare? **DA APPROFONDIRE**. (La prima sarebbe Instagram o l'utente che definisce questi nodi scheduler e distribuisce verso i nodi edge/fog. La distribuzione è un servizio offerto dal provider AWS o Cloudflare ad esempio. Però così facendo l'utente ha un bel onere nel scrivere un Application Orchestrator. Allora potrebbe essere invece che vi siano Application Orchestrator già esistenti offerti da AWS/Cloudflare?)
  - Il **Resource Scheduler**, su richiesta dell'Application Scheduler, che a sua volta si basa sui Requirements dell'Application, risponde con un'offerta contenente le informazioni dei nodi Worker che meglio soddisfanno i requisiti. Per fare ciò mantiene un **Registry** dei Worker attivi. Esegue quindi una query verso il Registry per conoscere i Workers disponibili.
    -  Preferisce nodi geograficamente vicino all'Application, in modo da essere vicini ai dati. Inoltre deve essere cosciente delle capabilities dei Workers tramite il Registry. Aggiorna la parte di **Resource Management** del Registry.
    - Gestisce in qualche modo anche le chiavi che permettano l'autenticazione e autorizzazione per la comunicazione tra Application Scheduler e Workers.
    - Il Resource Scheduler è di tipologia decentralizzato monolite, ovvero esistono diverse repliche distribuite dello Scheduler che gestiscono una porzione delle richieste ma implementano le stesse policies. È la tipologia di Kubernetes e Docker Swarm.
    - Ogni replica gestisce una sottoporzione dei nodi Workers geograficamente assegnati e _**non vi è sovrapposizione tra cluster di repliche diverse**_. Le risorse in un cluster sono principalmente statiche salvo fallimenti hardware, in quanto costituiti principalmente da dispositivi embedded e fog. Lo Scheduler cerca di sfruttare al pieno possibile le risorse di cui dispone.
    - Durante la mobilità, i dispositivi mobile dei partecipanti sono gli unici che verosimilmente abbandonano e si uniscono a nuovi cluster. Spostandosi di luogo cambia anche la replica dello Scheduler a cui fanno riferimento. Andranno quindi gestiti in maniera particolare, tenendo conto di fattori come il fatto che alle persone interessa aiutare nella computazione solo dei loro stessi dati. **DA APPROFONDIRE**.
  - L'**Admission Control** determina la soddisfacibilità dei Requirements, può quindi negare la richiesta nel caso in cui il cluster non disponga delle risorse necessarie per soddisfare i Requirements.
  - Il **Registry** contiene lo stato del sistema distribuito, ad esempio le locazioni dei Workers ed il loro stato di disponibilità. Essendo che non vi è sovrapposizione di nodi tra repliche dello scheduler, non dovrebbe servire uno store distribuito consistente come `etcd` di Kubernetes.
    - Contiene anche le informazioni per adempiere il ruolo da Resource manager. L'esecuzione delle funzioni è stateless e non richiede che rimanga attiva alcuna risorsa al termine dell'esecuzione, esattamente come avviene per funzioni serverless. Tuttavia il Resource Manager mantiene informazioni quali utilizzo di RAM, memoria persistente e quante funzioni sono già attive nei Workers.
  - **Gateway**: l'idea è che l'invio di funzioni e dati non coinvolga il Resource Scheduler, ma allo stesso tempo l'Application Scheduler non comunichi direttamente con i Workers, per ad esempio supportare la fault tolerancy senza che sia a carico dell'Application Scheduler.
    - Il Resource Scheduler ritorna all'Application i nomi dei Workers con cui può comunicare come risorse assieme all'URL del Gateway. L'Application invierà quindi dati e URL delle funzioni via il Gateway attraverso richieste REST. Il Gateway fa risoluzione dei Workers leggendo dallo storage del Registry ed inoltra le richieste. **DA APPROFONDIRE**.
    - Il load balancing non viene fatto dal Gateway rispetto ad un classico gateway in quanto si immagina sia più efficiente se l'Application Scheduler designa in anticipo i Workers sulla base dei Requirements, invece che lasciare la decisione al Gateway "on-the-fly" sulla base della singola richiesta REST. Di contro sarebbe più semplice per l'Application Scheduler non dover occuparsi del load balancing, però in ogni caso si occupa già di decidere ad esempio quali Workers usare per Map e quali per Reduce, con addirittura eventuali Worker come intermedi per lavorare sui dati intermedi.
- Un **Worker** è un nodo in grado di offrire capacità di computazione ad altri nodi del sistema. È in grado di descrivere le proprie capacità di computazione, come supporto a semplici operazioni CPU, operazioni a virgola mobile via FPU, operazioni SIMD o operazioni GPU.
  - Il **Kernel Runtime** dipende dal dispositivo ed offre le API di sistema per la concorrenza e l'I/O, che sono i due requisiti minimali. La concorrenza serve per eseguire più funzioni contemporaneamente, l'I/O per comunicare in rete via REST. Esempi di meccanismi di concorrenza offerti dal runtime sono processi o thread (OS), Ada/[RTIC](https://rtic.rs/0.5/book/en/) task (embedded), WebWorker (browser).
    - Le funzioni non sono preemptable al momento, quindi non è richiesta preemption al runtime.
    - _Dovrebbe avere anche una Resource Policy nel caso si possa in futuro condividere memoria tra funzioni_.
  - Il **Worker agent** comunica con l'Application Scheduler per aggiornare lo stato di disponibilità. Un esempio è il `kubelet` di Kubernetes.
  - Il **WASM Host** fornisce operazioni sul runtime HOST come risorse REST per l'Application Scheduler o chiamate API per il Worker Agent.
    - Espone endpoint REST che descrive le proprie risorse
    - Espone anche endpoint REST che permette di aggiungere una funzione URL e relativi dati ad una coda di job. La funzione viene scaricata dal Functions repository e messa in cache in caso di ulteriori richieste future. La coda permette invece di ridurre il tempo di attesa tra un job e l'altra.
  - Il **WASM Runtime** è l'ambiente di esecuzione virtuale delle funzioni. Se il Worker utilizza un interprete allora la funzione non è istanziata, altrimenti se utilizza un compilatore JIT o AOT l'istanza viene preservata per qualche minuto per permettere riuso più veloce.
    - Può avviare più functions in parallelo sfruttando l'isolamento di memoria offerto da WASM e il meccanismo di concorrenza del runtime.
    - La funzione implementa internamente stack e heap secondo il runtime di linguaggio ed usando la memoria lineare WASM.

## Implementazione proposta

La tesi implementerà una versione semplificata del sistema descritto sopra.

- Il runtime per i nodi browser è implementato all'interno di un browser attuale, Google Chrome e/o Firefox. Idealmente in futuro le applicazioni utente (mobile, tablet e desktop) sono tutte applicazioni web ed il sistema operativo è direttamente il browser (Ariadne), senza quindi incorrere nell'onere attuale ove le applicazioni web girano in un browser come processo in user-space dell'OS
- Un formato che permetta di trasmettere dati e funzioni, come rappresentazione di una risorsa REST. Le funzioni sono simili alle funzioni lambda del serverless-computing
- La computazione esegue diversi modelli leggeri di Deep Learning per immagini come esempio di filtri su video.
    - [CoCo SSD per l'object detection](https://github.com/tensorflow/tfjs-models/tree/master/coco-ssd)
    - [Blazeface per face recognition](https://github.com/tensorflow/tfjs-models/tree/master/blazeface)
    - [Body-pix per person segmentation](https://github.com/tensorflow/tfjs-models/tree/master/body-pix)
- La computazione esegue solo inferenza, non training. Al momento [Tensorflow supporta solo sperimentalmente WASM come back-end](https://blog.tensorflow.org/2020/03/introducing-webassembly-backend-for-tensorflow-js.html) e solo per alcune funzioni kernel (nel significato attribuito in ML, non nel mondo del system programming). Ciò significa che potenzialmente:
    - I modelli sopra potrebbero cambiare se utilizzano funzioni kernel non supportate dal back-end WASM
    - La libreria utilizzata potrebbe non essere Tensorflow in quanto rimane il problema del trasformare in WASM il codice front-end che definisce il modello. Un esempio di alternativa è [ONNX](https://github.com/microsoft/onnxjs) o [SSVM](https://github.com/second-state/ssvm).
    - I modelli potrebbero essere scritti from scratch in Rust nel caso in cui le strade precedenti non diano i risultati sperati. Chiaramente il valore del risultato sarebbe meno significativo rispetto al dimostrare di poter usare una libreria come Tensorflow, ma magari è possibile fare comunque un risultato discreto se fossero utilizzate istruzioni SIMD in Rust, che tuttavia è al momento solo una [RFC con implementazione sperimentale](https://github.com/rust-lang/rfcs/pull/2366).
    - Limitandosi all'inferenza, non vi è bisogno al momento di implementare uno stato globale condiviso che permetta un'efficiente training dei modelli.
    - Ogni funzione è eseguita da un solo nodo designato. Non vi è al momento provisioning automatico di ulteriori nodi nel caso di funzioni CPU-intensive.
- Il runtime per embedded, denominato Fedra, permette al dispositivo di partecipare alla computazione distribuita.
    - Fornisce endpoint REST che descrive le proprie risorse oltre alla possibilità, senza via REST, di ricevere dati e funzioni da eseguire.
    - Permette di eseguire funzioni in concorrenza. Il modello di concorrenza più opportuno, via thread o async ad esempio, è ancora da definire.
    - Possiede uno scheduler pensato appositamente per il sistema in oggetto. Anche in questo caso i dettagli sono ancora da definire, ad esempio se debba prediligere la reattività del servizio a discapito del response-time delle funzioni o se invece debba prediligere una esecuzione fair delle funzioni
    - Supporta STM32F4219 quindi con 2MB di memoria flash e 256KB di RAM. Dimostrare che il runtime può eseguire sulla famiglia STM32F4 è importante per la sua utilità per evitare che sia usabile solo con Raspberry Pi, le cui risorse hardware sono più vicine a quelle di un dispositivo utente che embedded. Anche a questo fine potrebbe essere necessario scrivere modelli più piccoli in Rust no-std invece che Tensorflow. STM32F429 è dotato però di Cortex-M4 che dovrebbe supportare istruzioni SIMD.
- Il runtime per cloud/fog è un porting di Fedra per x86_64. Ulteriori dettagli non sono conosciuti al momento, si spera solo in porting non doloroso ma gli imprevisti sono dietro l'angolo. Sicuramente il supporto ad architetture CPU diverse è considerato fin dall'inizio dello sviluppo di Fedra però.
    - Non supporta al momento container. Però nel caso di proseguimento dei lavori dopo la tesi, una prima aggiunta interessante sarebbe proprio l'implementazione dello standard WASI per chiamate di sistema e a seguire un layer di compatibilità per chiamate di sistema Linux in modo da supportare container. [BottleRocket di AWS](https://github.com/bottlerocket-os/bottlerocket) è una buona ispirazione, come pure [gVisor di Google](https://github.com/google/gvisor).
- Le diverse versioni di Fedra per embedded e cloud, oltre che potenzialmente essere la base per Ariadne ricordano le edizioni di Fedora, ovvero Fedora Workstation, Fedora CoreOS, Fedora IoT. Inoltre "Fedora" e "Fedra" distano come parole solo della vocale "o", motivo che ha portato al nome Fedra nella versione italiana invece che Phaedra. Le conoscenze di Fedora però sono limitate alla pagina Wikipedia al momento.
- Implementazioni esistenti:
    - [FAASM](https://www.usenix.org/conference/atc20/presentation/shillaker)
        - Orientato per HPC con stato globale condiviso e strategie per condividere anche lo stato locale. Tuttavia è orientato per il serverless, ovvero provisioning delle risorse per una sola funzione, mentre lo scenario della tesi presenta diverse funzioni appartenenti un workflow.
        - Esegue come processo Linux, di cui sfrutta i meccanismi di sicurezza come namespace e iptables
    - [Wascc Lattice](https://wascc.dev/docs/lattice/howitworks/)

        ![images/fig4.png](images/fig4.png)

        - L'immagine sopra è un lattice globale, dove ogni funzione è un attore e le capabilities sono processi separati con cui gli attori comunicano via messaggio. I messaggi sono inviati via protocollo NATS.

        ![images/assembly-mechs--beyond-wasmdome-(1).png](images/assembly-mechs--beyond-wasmdome-(1).png)

        - L'immagine sopra descrive una rete lattice dove i nodi sono orchestrati da Kubernetes tramite la libreria [Krustlet](https://github.com/deislabs/krustlet) installata su ogni nodo. I nodi però comunicano tra di loro via [NATS](https://nats.io/) senza Kubernetes. La rete rappresenta un gioco alla [crobots](https://en.wikipedia.org/wiki/Crobots) con player distribuiti, ognuno avente una strategia diversa.
        - Il lattice di Wascc è l'implementazione più vicina al sistema dello scenario descritto. Possiede infatti nodi distribuiti nella rete, che eseguono codice portabile WASM. Wascc inoltre supporta anche hot swapping dei moduli attori senza downtime.
        - I suoi difetti sono tuttavia possibilmente i seguenti:
            - Non è pensato per il sistema dello scenario, ad esempio non sono presenti nodi browser. Quest'ultimi si limitano a mostrare l'interfaccia del gioco (WebUI in immagine), senza essere parte fondamentale del sistema.
            - È una libreria e quindi richiede OS sottostante per poter operare. Inoltre significa che ottimizzazioni come uno scheduler pensato appositamente per il sistema devono essere implementate in user-space.
            - È orchestrato da Kubernetes che si occupa di fare provisioning, non di decidere, comporre e governare i nodi necessari per un workflow. Tuttavia in realtà il lattice Wascc non assume utilizzo necessariamente con Kubernetes.
            - Comunica via messaggi tramite protocollo NATS. Questa forma di comunicazione non è ricca come REST, che permette di definire in maniera uniforme risorse e servizi assieme ad una interfaccia comune per operare su questi. Ciò è fondamentale per un sistema eterogeneo come quello della tesi. Inoltre non è verificata la bontà del protocollo NATS per dispositivi embedded, rispetto ad esempio [CoAP](https://ieeexplore.ieee.org/document/6159216) che implementa REST su UDP.
            - Non si può nascondere che comprendere quali siano i reali difetti di Wascc rispetto al sistema dello scenario sia importante. Attualmente sembrerebbe che lo svantaggio principale sia essere una libreria, che quindi non può eseguire bare-metal ed esser compilata senza libreria standard. Questo lo rende quindi non idoneo per l'embedded con dispositivi resource-constrained, però a parte ciò sembra un'implementazione esistente molto interessante da cui prendere spunto.
