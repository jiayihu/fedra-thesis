# Fedra

**_Il testo in corsivo da considerarsi come una vaga idea, senza fondamenta di approfondimento._**

## Scenario

- Degli amici sono in spiaggia a divertirsi. Per immortalare il momento decidono di realizzare una video (story) tutti insieme. Una volta registrato il video, l'applicazione chiede all'utente di aggiungere i tag delle altre persone o di confermare gli utenti suggeriti tramite analisi del video. Confermati i partecipanti del video, l'utente può decidere i filtri da applicare al video.
- La computazione dei filtri avviene in maniera distribuita tra i partecipanti del video, che divengono volunteer nella computazione previo opt-in da parte loro. Il dispositivo utente da cui avviene l'editing elabora i requisiti della computazione e può partecipare nella computazione nei limiti delle sue risorse. Invia dunque i requisiti ad un orchestratore che si occuperà di trovare le risorse adeguate ed eseguire la computazione fino al raggiungimento dell'obiettivo. La distribuzione della computazione è un compito che richiede trasmissione sia di dati (il video) che di funzioni in quanto i filtri sono scaricabili e realizzabili dagli utenti di Instagram a disposizione per tutti tramite l'applicazione.
- Tuttavia qualora il dispositivo mobile non sia dotato di hardware dedicato per le operazioni AI o abbiano batteria insufficiente, il software può richiedere la collaborazione di altri nodi nella rete dotati delle opportune risorse hardware (ad esempio GPU o CPU con istruzioni SIMD) tenendo in conto del vincolo di latenza.
- Ogni dispositivo del sistema che si registri come disponibile ad offrire computazione descrive le proprie capacità, fornendo informazioni quali potenza di calcolo disponibile e caratteristiche hardware come GPU, encoder/decoder di video/immagini, supporto istruzioni SIMD
- A seconda dei requisiti, ad esempio del filtro da applicare, un orchestratore decide quale nodo di computazione del sistema il più adatto, includendo se stesso tra le opzioni.
- All'improvviso i diversi ragazzi ricevono avvisi sui propri cellulari riguardo ad un imminente pioggia in arrivo grazie ai sensori di meteo di cui sono dotati le loro case. Si dirigono allora verso le proprie case.
- Nel tragitto uno di loro continua l'editing del video in macchina. I dispositivi mobile dei ragazzi rimangono partecipanti nella computazione, mentre altri nodi possono essere rimossi o aggiunti dinamicamente durante il movimento in base alla distanza fisica o alla latenza.
- Arrivati a casa di uno dei ragazzi, decidono di passare al desktop per avere uno schermo più grande con cui proseguire l'editing. A quel punto è il desktop che definisce i nuovi requisiti della computazione, sostituendo il dispositivo mobile che diviene semplice volunteer aggiuntivo e poiché sono collegati alla rete di casa, perfino il dispositivo IoT usato come sensore meteo può eseguire della computazione extra CPU o GPU.
- **Elementi innovativi**:
  - Computazione distribuita a partecipazione dinamica: i nodi volunteer non sono fissi a priori e non conoscono le funzioni prima di unirsi alla computazione. Lavori precedenti di questo genere sono nell'ambito del **Volunteer Computing**.
  - L'applicazione utente definisce i requisiti della computazione o potenzialmente sono gli utenti che definiscono i requisiti. Questo si distacca dall'approccio attuale ove i fornitori di servizi definiscono i requisiti e le dipendenze, tramite un file statico per un orchestratore come Kubernetes.
  - _Continuità dello stato della computazione. In questo caso il video a cui vengono applicati gli effetti rappresenta lo stato della computazione. Nel passaggio a desktop, l'utente prosegue l'editing del video senza dover esplicitamente caricare dal dispositivo mobile verso il desktop. Questo può essere possibile usando un Distributed File System._
  - Trasferimento di dati e funzioni. Le funzioni sono sia scaricabili dalla rete (pull) che trasmissibili da un nodo all'altro (push). **MapReduce** è un'architettura di questo genere, dove tuttavia le funzioni non sono portabili su dispositivi etereogenei con runtime diversi.
  - Continuità di computazione: tutti i nodi della rete possono offrire computazione e allo stesso tempo scaricare parte di computazione verso altri nodi.

## Architettura

![](images/architecture.png)

- Una **Application** è un software che ha necessità di risorse per raggiungere un obiettivo. Può essere ad esempio un'applicazione web, mobile o microservice in cloud. Un'applicazione è composta di **Task**, la cui rappresentazione è una **funzione**. Il media type di questa rappresentazione è WASM.
  - Le funzioni sono registrate nel **Functions Repository** al momento da parte dell'Application.
  - Un **Requirement** è una descrizione formale delle risorse, attualmente solo di computazione, richieste da una Application. Contiene le informazioni sulle funzioni quali i requisiti di memoria RAM di ciascuna funzione, le capabilities richieste (ad esempio TCP handle), e potenzialmente altre informazioni come la descrizione delle dipendenze tra funzioni.
    - I requisiti di risorse RAM possono essere specificate in maniera granulare grazie al determinismo di esecuzione dei moduli WASM, in particolare usando runtime di linguaggi senza garbage-collector come Rust. Questo aspetto, unito al basso overhead di memoria dei moduli WASM, permette un maggior utilizzo delle risorse nei cluster, permettendo di eseguire più moduli sullo stesso nodo.
    - Vi sono diversi modi di specificare le dipendenze tra funzioni, ad esempio come gruppi di Task dipendenti nello stesso nodo (Pod) in Kubernetes, oppure come grafo nel caso di Microsoft Apollo.
    - Un altro esempio di Requirement potrebbe essere [AWS Cloudformation](https://aws.amazon.com/it/cloudformation/), che offre sia API che template statico per fare provisioning automatico delle risorse necessarie in un sistema distribuito su AWS.
    - L'esempio preferito attualmente è il modello **MapReduce** di Google. Permette alle applicazioni di descrivere facilmente una specifica della computazione tramite combinazione di funzioni Map `(key, value) => list(key, value)` e Reduce `(key, list(value)) => list(value)`.
      - Fornisce un modello di programmazione semplice senza che le applicazioni debbano preoccuparsi dei problemi della computazione distribuita.
      - È un modello di computazione distribuita che si è dimostrata flessibile per diverse tipologie di problemi.
      - Si presta bene anche come caso d'uso per il resto dell'architettura. I nodi **Workers** ricevono in ingresso i dati input e la funzione Map/Reduce.
      - Chi si occupa però dell'orchestrazione delle funzioni MapReduce? Ovvero c'è bisogno di assegnare le funzioni Map ed i dati ai Workers, aggregare gli output intermedi, fare split di questi per chiave ed inviati ai Worker con funzioni Reduce. Non può essere l'**Orchestrator** classico alla Kubernetes in quanto è generico rispetto all'Application ed inoltre non potrebbe contenere tutti gli stati di computazione delle diverse Application. La scelta ritenuta più ragionevole al momento è utilizzare uno **scheduling a due livelli**, diviso in **Application Scheduler** e **Resource Scheduler**. Descritto più in avanti.
      - Rimane comunque il problema di dove salvare i dati di computazione intermedi. Se si suppone che le Application avranno requisiti compute-intensive e non data-intensive si potrebbe salvare lo stato intermedio nell'Application Scheduler. Questo però limiterebbe il genere di applicazioni eseguibili nel sistema. Un'altra alternativa sarebbe usare nodi storage, ad esempio un nodo Blob Storage o Key-Value Storage, ma questi in genere sono presenti in datacenter del cloud. *Invece un distributed file system (DFS) potrebbe essere la soluzione migliore*.
    - *Invece di inviare la coppia dati input ("raw") e funzione (tramite URL), si potrebbe inviare la tripletta dati input, funzione e locazione dell'output tutto tramite URL. L'URL quindi permette anche di definire il protocollo e locazione dove poter leggere o salvare i dati. L'idea arriva dal concetto ["Everything is a URL" di Redox](https://doc.redox-os.org/book/ch04-04-urls.html).* Un altro esempio sono i pre-signed URLs di AWS che permettono di leggere e scrivere in maniera ristretta sullo storage S3.
- **Functions Repository**: è un registro delle funzioni identificabili in maniera univoca come risorsa URL. Le funzioni hanno una scadenza automatica se non sono state usate ad esempio nelle ultime 24h. Il Repository è geograficamente vicino ai Workers per migliorare il tempo di risposta.
  - L'idea è avere un registry di funzioni simili alle immagini dei container ma molto più minimali ancora, sull'ordine di magari decine o centinaia di KB invece che decine di MB.
- L'**Orchestrator** è diviso in due livelli. Il livello **Application Scheduler** si occupa di fare scheduling delle funzioni, mentre il **Resource Scheduler** è responsabile dell'assegnazione dei nodi Workers e del monitoraggio del loro stato di disponibilità. L'architettura è ispirata da Apache Mesos e Apache YARN.
  - I requisiti dell'Orchestrator sono:
    1. Scalabilità/Availability
    2. Multi-tenancy: deve supportare più Application con diverse esigenze contemporaneamente
    3. Locality awareness: deve permettere di coordinare tenendo in conto della posizione geografica dell'Application, dei dati e dei Workers
    4. High-utilization del cluster
    5. Affidabilità: il fallimento di un nodo, seppur importante quanto uno scheduler, non deve comportare la perdita di tutte le funzioni di tutte le Application.
    6. Sicurezza e auditing delle operazioni
    7. Supporto per diversità di modelli di programmazione: MapReduce è solo uno di questi, deve essere possibile implementare altri modelli più adatti per ad esempio Machine Learning o Video encoding/decoding.
  - Questa architettura rende flessibile lo scheduling dei Workers per diversi tipi di Application. In particolare funziona meglio per tipologie di tasks a breve termine, che non occupino la risorsa a lungo. Questo sembra essere proprio il caso di Workers situati su nodi embedded o browser.
  - L'**Application Scheduler** riceve le informazioni dei nodi Worker disponibili e decide come assegnare le funzioni ai nodi. Punta a fare load balancing tra i Workers, ma allo stesso tempo cerca di fare cache-hit con Workers che abbiano già in cache la funzione per migliorare il tempo di risposta.
    - L'Application Scheduler **NON** è definito dal sistema, ovvero è definibile dagli utenti per permettere maggiore flessibilità di Applicazioni. Come si fa però a definirlo? E su che nodi esegue? Come fa l'applicazione a conoscere l'Application Scheduler da contattare? **DA APPROFONDIRE**. (La prima sarebbe Instagram o l'utente che definisce questi nodi scheduler e distribuisce verso i nodi edge/fog. La distribuzione è un servizio offerto dal provider AWS o Cloudflare ad esempio. Però così facendo l'utente ha un bel onere nel scrivere un Application Orchestrator. Allora potrebbe essere invece che vi siano Application Orchestrator già esistenti offerti da AWS/Cloudflare?)
    - Avere l'Application Scheduler disaccoppiato dal Resource Scheduler permette però di coordinare in maniera efficiente dipendenze e comunicazioni tra funzioni, aspetto oggi non possibile con serverless.
    - L'Application Scheduler esegue su un nodo fog del cluster. Potrebbe l'Application richiedere al Resource Worker di attivare un Application Scheduler scaricando un container da Docker register ed eseguendolo come servizio su un nodo fog del cluster?
  - Il **Resource Scheduler**, su richiesta dell'Application Scheduler, che a sua volta si basa sui Requirements dell'Application, risponde con un'offerta contenente le informazioni dei nodi Worker che meglio soddisfanno i requisiti. Per fare ciò mantiene un **Registry** dei Worker attivi. Esegue quindi una query verso il Registry per conoscere i Workers disponibili.
    -  Preferisce nodi geograficamente vicino all'Application, in modo da essere vicini ai dati. Inoltre deve essere cosciente delle capabilities dei Workers tramite il Registry. Aggiorna la parte di **Resource Management** del Registry.
    - È consentito condividere un Worker tra più richieste di diversi Application Schedulers.
    - Gestisce in qualche modo anche le chiavi che permettano l'autenticazione e autorizzazione per la comunicazione tra Application Scheduler e Workers.
    - Il Resource Scheduler è di tipologia decentralizzato monolite, ovvero esistono diverse repliche distribuite dello Scheduler che gestiscono una porzione delle richieste ma implementano le stesse policies. In questo modo si è in grado di offrire high-availability agli Application Schedulers. È la tipologia di Kubernetes e Docker Swarm.
    - Ogni cluster è dotato di Resource Scheduler leader con repliche e _**non vi è sovrapposizione tra cluster di Resource Scheduler leader diversi**_. Le risorse in un cluster sono principalmente statiche salvo fallimenti hardware, in quanto costituiti principalmente da dispositivi embedded e fog. Lo Scheduler cerca di sfruttare al pieno possibile le risorse di cui dispone.
    - Il Resource Scheduler è agnostico della finalità dei Worker, tratta il cluster di risorse eterogenee come un continuum
    - In una versione avanzata di Resource Scheduler, è possibile salvare lo stato di memoria di una funzione. Questo può essere utile per fare preemption oppure per migrare la computazione verso un altro Worker. 
  - L'**Admission Control** determina la soddisfacibilità dei Requirements, può quindi negare la richiesta nel caso in cui il cluster non disponga delle risorse necessarie per soddisfare i Requirements.
  - Il **Registry** contiene lo stato del sistema distribuito, ad esempio le locazioni dei Workers ed il loro stato di disponibilità. Può utilizzare come stato uno store key-value distribuito consistente come `etcd` di Kubernetes.
    - Contiene anche le informazioni per adempiere il ruolo da Resource manager. L'esecuzione delle funzioni è stateless e non richiede che rimanga attiva alcuna risorsa al termine dell'esecuzione, esattamente come avviene per funzioni serverless. Tuttavia il Resource Manager mantiene informazioni quali utilizzo di RAM, memoria persistente e quante funzioni sono già attive nei Workers.
  - **Gateway**: l'idea è che l'invio di funzioni e dati non coinvolga il Resource Scheduler, ma allo stesso tempo l'Application Scheduler non comunichi direttamente con i Workers, per ad esempio supportare la fault tolerancy senza che sia a carico dell'Application Scheduler.
    - Il Resource Scheduler ritorna all'Application Scheduler le informazioni dei Workers con cui può comunicare come risorse REST assieme all'URL del Gateway. L'Application Scheduler invierà quindi dati e URL delle funzioni via il Gateway attraverso richieste REST. Il Gateway fa risoluzione dei Workers leggendo dallo storage del Registry, salva in cache il mapping nomi-IP, ed inoltra le richieste. **DA APPROFONDIRE**.
    - Il load balancing non viene fatto dal Gateway rispetto ad un classico gateway in quanto si immagina sia più efficiente se l'Application Scheduler designa in anticipo i Workers sulla base dei Requirements, invece che lasciare la decisione al Gateway "on-the-fly" sulla base della singola richiesta REST. Di contro sarebbe più semplice per l'Application Scheduler non dover occuparsi del load balancing, però in ogni caso si occupa già di decidere ad esempio quali Workers usare per Map e quali per Reduce, con addirittura eventuali Worker come intermedi per lavorare sui dati intermedi.
- Un **Worker** è un nodo in grado di offrire capacità di computazione ad altri nodi del sistema. È in grado di descrivere le proprie capacità di computazione, come supporto a semplici operazioni CPU, operazioni a virgola mobile via FPU, operazioni SIMD o operazioni GPU.
  - Il **Platform Runtime** dipende dal dispositivo ed offre le API di sistema per la concorrenza e l'I/O, che sono i due requisiti minimali. La concorrenza serve per eseguire più funzioni contemporaneamente, l'I/O per comunicare in rete via REST. Esempi di meccanismi di concorrenza offerti dalla piattaforma sono processi o thread (OS), Ada/[RTIC](https://rtic.rs/0.5/book/en/) task (embedded), WebWorker (browser).
    - Le funzioni non sono preemptable al momento, quindi non è richiesta preemption al runtime.
    - _Dovrebbe avere anche una Resource Policy nel caso si possa in futuro condividere memoria tra funzioni_.
  - Il **Worker agent** comunica con l'Application Scheduler per aggiornare lo stato di disponibilità. Un esempio è il `kubelet` di Kubernetes.
  - Il **WASM Host** fornisce operazioni sul runtime HOST come risorse REST per l'Application Scheduler o chiamate API per il Worker Agent.
    - Espone endpoint REST che descrive le proprie risorse
    - Espone anche endpoint REST che permette di aggiungere una funzione URL e relativi dati ad una coda di job. La funzione viene scaricata dal Functions repository e messa in cache in caso di ulteriori richieste future. La coda permette invece di ridurre il tempo di attesa tra un job e l'altra.
  - Il **WASM Runtime** è l'ambiente di esecuzione virtuale delle funzioni. Se il Worker utilizza un interprete allora la funzione non è istanziata, altrimenti se utilizza un compilatore JIT o AOT l'istanza viene preservata per qualche minuto per permettere riuso più veloce.
    - Può avviare più functions in parallelo sfruttando l'isolamento di memoria offerto da WASM e il meccanismo di concorrenza del runtime.
    - La funzione implementa internamente stack e heap secondo il runtime di linguaggio ed usando la memoria lineare WASM.
  - Vale davvero la pena avere nodi Workers sui browsers? Chiaramente poter sfruttare tutta la potenza mobile sarebbe molto vantaggiosa, ma ci sono diversi limiti tecnologici con i browser.
    - Non è possibile eseguire attività in background se la pagina non è attiva, anche (ab)usando tecnologie come `BackgroundSync` e `ServiceWorker`.
    - Un browser non può divenire un server che espone endpoint REST. Per comunicare col browser bisogna usare il protocollo WebSocket. WebRTC è solo tra browsers. WebSocket significa che un server deve rimanere attivo per inoltrare le richieste dall'Application Orchestrator al Worker. Questo server potrebbe essere direttamente il Gateway ma rischia di diventare bottleneck. Un server intermediario in più invece peggiorerebbe la latenza e complicherebbe il sistema. Magari invece potrebbe essere che l'Application Scheduler gestisca direttamente la comunicazione con i browser Workers, in quanto la loro partecipazione alla computazione è già dipendente dall'applicazione. *Inoltre REST è un'architettura che non obbliga ad alcun protocollo, per cui "REST over WebSocket" sarebbe possibile.*
  - Discorso analogo per in generale mobile, anche nativo. Le applicazioni sono sempre limitate nelle attività background ed inoltre l'interesse verso aiutare computazioni di terzi è di interesse limitato per le persone. Si distingue quindi tra Workers a **partecipazione dinamica** e a **partecipazione statica**. I nodi a partecipazione dinamica, ovvero browser o mobile, si collegano via WebSocket all'Application Orchestrator e la comunicazione tra le due parti è diretta. Non hanno bisogno di Resource Scheduler in quanto non sono multi-tenant. La fault tolerancy viene invece gestita dall'Application Scheduler e sono esclusi da applicazioni che non hanno interesse in utenti workers.

## Contorno di tesi

Per evitare la "second system syndrome", la tesi cercherà di riusare al più possibili soluzioni software esistenti senza snaturare l'architettura del sistema.

- Implementazioni esistenti:


        - L'immagine sopra è un lattice globale, dove ogni funzione è un attore e le capabilities sono processi separati con cui gli attori comunicano via messaggio. I messaggi sono inviati via protocollo NATS.

        ![images/assembly-mechs--beyond-wasmdome-(1).png](images/assembly-mechs--beyond-wasmdome-(1).png)

        - L'immagine sopra descrive una rete lattice dove i nodi sono orchestrati da Kubernetes tramite la libreria [Krustlet](https://github.com/deislabs/krustlet) installata su ogni nodo. I nodi però comunicano tra di loro via [NATS](https://nats.io/) senza Kubernetes. La rete rappresenta un gioco alla [crobots](https://en.wikipedia.org/wiki/Crobots) con player distribuiti, ognuno avente una strategia diversa.
        - Il lattice di Wascc è l'implementazione più vicina al sistema dello scenario descritto. Possiede infatti nodi distribuiti nella rete, che eseguono codice portabile WASM. Wascc inoltre supporta anche hot swapping dei moduli attori senza downtime.
        - I suoi difetti sono tuttavia possibilmente i seguenti:
            - Non è pensato per il sistema dello scenario, ad esempio non sono presenti nodi browser. Quest'ultimi si limitano a mostrare l'interfaccia del gioco (WebUI in immagine), senza essere parte fondamentale del sistema.
            - È una libreria e quindi richiede OS sottostante per poter operare. Inoltre significa che ottimizzazioni come uno scheduler pensato appositamente per il sistema devono essere implementate in user-space.
            - È orchestrato da Kubernetes che si occupa di fare provisioning, non di decidere, comporre e governare i nodi necessari per un workflow. Tuttavia in realtà il lattice Wascc non assume utilizzo necessariamente con Kubernetes.
            - Comunica via messaggi tramite protocollo NATS. Questa forma di comunicazione non è ricca come REST, che permette di definire in maniera uniforme risorse e servizi assieme ad una interfaccia comune per operare su questi. Ciò è fondamentale per un sistema eterogeneo come quello della tesi. Inoltre non è verificata la bontà del protocollo NATS per dispositivi embedded, rispetto ad esempio [CoAP](https://ieeexplore.ieee.org/document/6159216) che implementa REST su UDP.
            - Non si può nascondere che comprendere quali siano i reali difetti di Wascc rispetto al sistema dello scenario sia importante. Attualmente sembrerebbe che lo svantaggio principale sia essere una libreria, che quindi non può eseguire bare-metal ed esser compilata senza libreria standard. Questo lo rende quindi non idoneo per l'embedded con dispositivi resource-constrained, però a parte ciò sembra un'implementazione esistente molto interessante da cui prendere spunto.
